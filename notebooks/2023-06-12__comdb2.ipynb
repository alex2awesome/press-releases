{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2766cab4-0516-4512-ba51-01afc61e7926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from comdb2 import dbapi2\n",
    "import pandas as pd \n",
    "from datetime import datetime, date\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea94886-7d6f-4fda-986b-09fcf2d55b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = \"nanadb\"\n",
    "connection = dbapi2.connect(db_name, autocommit=True, tier=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "804793a1-3e36-4b11-a575-e4f2f7e8c1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched 0 rows...\n",
      "fetched 5 rows...\n",
      "fetched 10 rows...\n",
      "fetched 15 rows...\n",
      "fetched 20 rows...\n",
      "fetched 25 rows...\n",
      "fetched 30 rows...\n",
      "fetched 35 rows...\n",
      "fetched 40 rows...\n"
     ]
    }
   ],
   "source": [
    "# Setting an appropriate SQL query\n",
    "num_rows_to_fetch = 500\n",
    "offset = 0\n",
    "fetched_dfs = []\n",
    "date_cutoff = date(2021, 6, 1)\n",
    "\n",
    "sql_query_big = f\"\"\"\n",
    "    with r1 as (\n",
    "            SELECT * from release \n",
    "             WHERE wire_id > 0 and wire_id NOT IN (25,2345,96,3543,584,474,1719,3447,586,587,97,2640)\n",
    "                AND CAST(toa AS DATE) > CAST('2023-01-01' AS DATE)\n",
    "    ),\n",
    "    story_nicode_grouped as (\n",
    "        SELECT suid, group_concat(nicode) as nicode from story_nicode group by suid\n",
    "    ),\n",
    "    story_ticker_grouped as (\n",
    "        select suid, group_concat(ticker) as ticker from story_ticker group by suid\n",
    "    ),\n",
    "    release_nicode_grouped as (\n",
    "        SELECT release_id, group_concat(nicode) as nicode from release_nicode group by release_id\n",
    "    ),\n",
    "    release_ticker_grouped as (\n",
    "        SELECT release_id, group_concat(ticker) as ticker from release_ticker group by release_id\n",
    "    ),\n",
    "    bullet_grouped as (\n",
    "        SELECT release_id, group_concat(text, '|||') as text from bullet group by release_id\n",
    "    )\n",
    "        SELECT\n",
    "            S.suid AS story_suid,\n",
    "            R.suid AS release_suid,\n",
    "            R.bundle_id AS release_bundle_id,\n",
    "            S.release_id AS release_id,\n",
    "            ST.name AS story_type,\n",
    "            RT.name AS release_type,\n",
    "            S.toa AS story_toa,\n",
    "            R.toa AS release_toa,\n",
    "            S.headline AS story_headline,\n",
    "            S.wire AS story_wire,\n",
    "            S.wire_class AS story_wire_class,\n",
    "            R.wire_id AS release_wire,\n",
    "            R.wire_class AS release_wire_class,\n",
    "            R.web_url AS release_web_url,\n",
    "            R.subject AS release_subject, \n",
    "            R.body AS release_body,\n",
    "            B.text AS bullet,\n",
    "            SNC.nicode AS story_nicode,\n",
    "            STR.ticker AS story_ticker,\n",
    "            RNC.nicode AS release_nicode,\n",
    "            RTR.ticker AS release_ticker\n",
    "            FROM story S\n",
    "            JOIN r1 R ON S.release_id = R.id\n",
    "            JOIN release_type RT ON R.release_type = RT.release_type\n",
    "            JOIN story_type ST ON S.story_type = ST.story_type\n",
    "            JOIN release_nicode_grouped RNC ON R.id = RNC.release_id\n",
    "            JOIN story_nicode_grouped SNC ON S.suid = SNC.suid\n",
    "            JOIN release_ticker_grouped RTR ON R.id = RTR.release_id\n",
    "            JOIN story_ticker_grouped STR ON S.suid = STR.suid\n",
    "            JOIN bullet_grouped B ON B.release_id = R.id\n",
    "            WHERE S.language = 'en'\n",
    "            AND R.language = 'en'\n",
    "\"\"\"\n",
    "\n",
    "sql_query_no_nicodes = f\"\"\"\n",
    "    with r1 as (\n",
    "            SELECT * from release \n",
    "             WHERE wire_id > 0 and wire_id NOT IN (25,2345,96,3543,584,474,1719,3447,586,587,97,2640)\n",
    "                AND CAST(toa AS DATE) > CAST('2023-01-01' AS DATE)\n",
    "    )\n",
    "        SELECT \n",
    "            S.suid AS story_suid,\n",
    "            R.suid AS release_suid,\n",
    "            R.bundle_id AS release_bundle_id,\n",
    "            S.release_id AS release_id,\n",
    "            ST.name AS story_type,\n",
    "            RT.name AS release_type,\n",
    "            S.toa AS story_toa,\n",
    "            R.toa AS release_toa,\n",
    "            S.headline AS story_headline,\n",
    "            S.wire AS story_wire,\n",
    "            S.wire_class AS story_wire_class,\n",
    "            R.wire_id AS release_wire,\n",
    "            R.wire_class AS release_wire_class,\n",
    "            R.web_url AS release_web_url,\n",
    "            R.subject AS release_subject, \n",
    "            R.body AS release_body\n",
    "            FROM story S\n",
    "            JOIN r1 R ON S.release_id = R.id\n",
    "            JOIN release_type RT ON R.release_type = RT.release_type\n",
    "            JOIN story_type ST ON S.story_type = ST.story_type\n",
    "            WHERE S.language = 'en'\n",
    "            AND R.language = 'en'\n",
    "\"\"\"\n",
    "    \n",
    "for idx, df in enumerate(\n",
    "    pd.read_sql(sql_query_no_nicodes, con=connection, chunksize=num_rows_to_fetch)\n",
    "):\n",
    "    df.to_csv(f'one-fetch-{idx}.csv')\n",
    "    if idx % 5 == 0:\n",
    "        print(f'fetched {idx} rows...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9718f-926a-4507-9234-c2110f1e9978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6a966-4655-4582-9391-2d3ac5591a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad00a5-8fcb-4758-b54d-3b99b1b0aa84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b0e0905-2fcb-441b-a7db-9856e43e15d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78fe492d-9117-4c7e-ba7e-cda086364238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [11:17<00:00, 16.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "fetched_files = glob.glob('one-fetch-*.csv')\n",
    "fetched_files = sorted(fetched_files, key=lambda x: int(re.search('-(\\d+).csv', x)[1]))\n",
    "\n",
    "dfs_sans_body = []\n",
    "body_dfs = []\n",
    "dump_every = 5\n",
    "proc_num = 0\n",
    "for i, f in tqdm(enumerate(fetched_files), total=len(fetched_files)):\n",
    "    df = pd.read_csv(f, index_col=0)\n",
    "    df_proc = df.loc[lambda df: df['release_body'].fillna('').str.strip() != '']\n",
    "    \n",
    "    bodies = df_proc[['release_suid', 'release_body']].drop_duplicates()\n",
    "    bodies['processed_release_body'] = (\n",
    "        bodies['release_body']\n",
    "            .apply(lambda x: BeautifulSoup(x).get_text().strip())\n",
    "            .apply(unidecode)\n",
    "            .drop(columns='release_body')\n",
    "    )\n",
    "    df_proc = df_proc.drop(columns='release_body')\n",
    "    dfs_sans_body.append(df_proc)\n",
    "    body_dfs.append(bodies)\n",
    "    \n",
    "    if i % dump_every == 0:\n",
    "        pd.concat(dfs_sans_body).to_csv(f'processed-nana-{proc_num}.csv')\n",
    "        pd.concat(body_dfs).to_csv(f'processed-nana-bodies-{proc_num}.csv')        \n",
    "        proc_num += 1\n",
    "        dfs_sans_body = []\n",
    "        body_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bc7cf-9ccc-43bd-b2c8-64d54b5cadfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d7bc955-6a37-46e5-ae7f-6efe4c8928ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_files = glob.glob('processed-nana-*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c733b61-97cf-4102-80ef-fbabd2253b81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed-nana-7.csv',\n",
       " 'processed-nana-2.csv',\n",
       " 'processed-nana-6.csv',\n",
       " 'processed-nana-3.csv',\n",
       " 'processed-nana-5.csv',\n",
       " 'processed-nana-0.csv',\n",
       " 'processed-nana-1.csv',\n",
       " 'processed-nana-8.csv',\n",
       " 'processed-nana-4.csv']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: 'bodies' not in x, processed_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a516531-6429-41bf-8fcb-9d3bcfb8d744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:11,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_files = glob.glob('processed-nana-*.csv')\n",
    "processed_files = sorted(processed_files, key=lambda x: int(re.search('-(\\d+).csv', x)[1]))\n",
    "\n",
    "all_processed_dfs = []\n",
    "all_processed_body_dfs = [] \n",
    "cutoff = 25\n",
    "num_combined = num_bodies_combined = 0\n",
    "for idx, p_filename in tqdm(enumerate(processed_files)):\n",
    "    df = pd.read_csv(p_filename, index_col=0)\n",
    "    if 'bodies' in p_filename:\n",
    "        all_processed_body_dfs.append(df)\n",
    "    else:\n",
    "        all_processed_dfs.append(df)\n",
    "    if int(idx / 2)  % cutoff == 0:\n",
    "        if len(all_processed_dfs) > 1:\n",
    "            pd.concat(all_processed_dfs).to_csv(\n",
    "                f'big-processed-nana-file-{num_combined}.csv.gz', compression='gzip'\n",
    "            )\n",
    "            num_combined +=1\n",
    "            all_processed_dfs = []\n",
    "        \n",
    "        if len(all_processed_body_dfs) > 1:\n",
    "            pd.concat(all_processed_body_dfs).to_csv(\n",
    "                f'big-processed-nana-file-bodies-{num_bodies_combined}.csv.gz', compression='gzip'\n",
    "            )\n",
    "            num_bodies_combined +=1\n",
    "            all_processed_body_dfs = []\n",
    "\n",
    "            \n",
    "pd.concat(all_processed_dfs).to_csv(\n",
    "    f'big-processed-nana-file-{num_combined}.csv.gz', compression='gzip'\n",
    ")\n",
    "pd.concat(all_processed_body_dfs).to_csv(\n",
    "    f'big-processed-nana-file-bodies-{num_combined}.csv.gz', compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c7bbbad8-9ae3-4b50-a9aa-e94fe2bb46f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_processed_df = pd.concat(all_processed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b445a-5e15-4f9d-999b-25fe6ad54da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2d705e1",
   "metadata": {},
   "source": [
    "# Wrap data from Comdb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1516b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c69ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "suid_rid_map_files = glob.glob('../data/zomo-downloads/*suids-rids*')\n",
    "suid_rid_maps = pd.concat(list(map(pd.read_excel, suid_rid_map_files)))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11681021",
   "metadata": {},
   "outputs": [],
   "source": [
    "suid_rid_maps.to_csv('../data/zomo-downloads/all_suid_rid_maps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e78117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28155f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f003813589945f79701ec424fb7003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on ../data/zomo-downloads/~$2023-01-01__2023-02-01__release-data.xlsx...\n"
     ]
    }
   ],
   "source": [
    "release_body_files = glob.glob('../data/zomo-downloads/*release*')\n",
    "release_bodies = [] \n",
    "\n",
    "for f in tqdm(release_body_files):\n",
    "    try:\n",
    "        release_bodies.append(pd.read_excel(f))\n",
    "    except:\n",
    "        print(f'failed on {f}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "789b050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_bodies_df = pd.concat(release_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b7f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4216d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf1641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcffbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167c527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16655ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052de7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c30544-36b3-4f98-8791-2c1d9a3a48a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
